# üñ•Ô∏è H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng vLLM + Langfuse tr√™n Server

## üéØ T√¨nh hu·ªëng

- B·∫°n ƒëang ·ªü tr√™n server Linux
- Ch·ªâ c√≥ terminal, kh√¥ng c√≥ GUI
- Mu·ªën xem traces t·ª´ Langfuse local

## üöÄ Setup

### 1. Kh·ªüi ch·∫°y h·ªá th·ªëng

```bash
# Start t·∫•t c·∫£ services
docker-compose up -d

# Ki·ªÉm tra status
docker-compose ps
```

### 2. Ki·ªÉm tra services ƒëang ch·∫°y

```bash
# Xem logs
docker-compose logs -f

# Ki·ªÉm tra ports
netstat -tlnp | grep -E ':(8000|8001|3000)'
```

## üìä C√°ch xem traces t·ª´ terminal

### Option 1: S·ª≠ d·ª•ng CLI tool (Khuy·∫øn ngh·ªã)

```bash
# C√†i ƒë·∫∑t dependencies
pip install tabulate

# Xem danh s√°ch traces
python langfuse_cli.py

# Xem chi ti·∫øt m·ªôt trace c·ª• th·ªÉ
python langfuse_cli.py --trace-id <trace_id>

# Xem traces trong 7 ng√†y qua
python langfuse_cli.py --days 7

# Xem 50 traces g·∫ßn nh·∫•t
python langfuse_cli.py --limit 50
```

### Option 2: S·ª≠ d·ª•ng curl

```bash
# L·∫•y danh s√°ch traces
curl "http://localhost:3000/api/public/traces?limit=10" | jq

# L·∫•y chi ti·∫øt trace
curl "http://localhost:3000/api/public/traces/<trace_id>" | jq

# L·∫•y observations
curl "http://localhost:3000/api/public/traces/<trace_id>/observations" | jq
```

### Option 3: Port forwarding (n·∫øu c√≥ SSH access)

```bash
# T·ª´ m√°y local, SSH v·ªõi port forwarding
ssh -L 3000:localhost:3000 -L 8000:localhost:8000 -L 8001:localhost:8001 user@server_ip

# Sau ƒë√≥ truy c·∫≠p t·ª´ browser local:
# http://localhost:3000 (Langfuse dashboard)
# http://localhost:8000 (API 1)
# http://localhost:8001 (API 2)
```

## üß™ Test API

### Test nhanh

```bash
# Test API 1
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [{"role": "user", "content": "Hello!"}],
    "max_tokens": 50,
    "trace_id": "test-1"
  }'

# Test API 2
curl -X POST http://localhost:8001/chat \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [{"role": "user", "content": "Hello!"}],
    "max_tokens": 50,
    "trace_id": "test-2"
  }'
```

### Test v·ªõi Python

```bash
python quick_test.py
```

## üìà Monitoring t·ª´ terminal

### 1. Xem logs real-time

```bash
# T·∫•t c·∫£ services
docker-compose logs -f

# Ch·ªâ vLLM API 1
docker-compose logs -f vllm-api-1

# Ch·ªâ vLLM API 2
docker-compose logs -f vllm-api-2

# Ch·ªâ Langfuse
docker-compose logs -f langfuse
```

### 2. Ki·ªÉm tra GPU usage

```bash
# Xem GPU usage
nvidia-smi

# Monitor GPU real-time
watch -n 1 nvidia-smi
```

### 3. Ki·ªÉm tra API health

```bash
# Health check API 1
curl http://localhost:8000/health

# Health check API 2
curl http://localhost:8001/health
```

## üîç Xem traces chi ti·∫øt

### S·ª≠ d·ª•ng CLI tool

```bash
# Xem danh s√°ch traces
python langfuse_cli.py

# Output s·∫Ω hi·ªÉn th·ªã:
# +------------+------------------+---------------------+--------+--------+----------+
# | Trace ID   | Name             | Timestamp           | Tokens | Status | Project  |
# +------------+------------------+---------------------+--------+--------+----------+
# | project-1- | project-1-chat   | 2024-01-15 10:30:15 | 45     | OK     | project-1|
# | project-2- | project-2-chat   | 2024-01-15 10:30:20 | 67     | OK     | project-2|
# +------------+------------------+---------------------+--------+--------+----------+

# Xem chi ti·∫øt trace c·ª• th·ªÉ
python langfuse_cli.py --trace-id project-1-abc123
```

### S·ª≠ d·ª•ng jq ƒë·ªÉ format JSON

```bash
# C√†i ƒë·∫∑t jq n·∫øu ch∆∞a c√≥
sudo apt-get install jq

# L·∫•y traces v√† format ƒë·∫πp
curl -s "http://localhost:3000/api/public/traces?limit=5" | jq '.data[] | {id, name, timestamp, status}'
```

## üõ†Ô∏è Troubleshooting

### Langfuse kh√¥ng kh·ªüi ƒë·ªông

```bash
# Ki·ªÉm tra logs
docker-compose logs langfuse

# Restart service
docker-compose restart langfuse
```

### API kh√¥ng response

```bash
# Ki·ªÉm tra logs
docker-compose logs vllm-api-1
docker-compose logs vllm-api-2

# Ki·ªÉm tra GPU
nvidia-smi

# Restart services
docker-compose restart vllm-api-1 vllm-api-2
```

### Kh√¥ng th·∫•y traces

```bash
# Ki·ªÉm tra k·∫øt n·ªëi gi·ªØa API v√† Langfuse
docker-compose logs vllm-api-1 | grep -i langfuse
docker-compose logs vllm-api-2 | grep -i langfuse

# Test API ƒë·ªÉ t·∫°o trace m·ªõi
python quick_test.py
```

## üìù Script h·ªØu √≠ch

### T·∫°o file `monitor.sh`

```bash
#!/bin/bash
echo "=== vLLM + Langfuse Monitor ==="
echo "Time: $(date)"
echo ""

echo "=== GPU Status ==="
nvidia-smi --query-gpu=name,memory.used,memory.total,utilization.gpu --format=csv

echo ""
echo "=== API Status ==="
curl -s http://localhost:8000/health | jq -r '.status'
curl -s http://localhost:8001/health | jq -r '.status'

echo ""
echo "=== Recent Traces ==="
python langfuse_cli.py --limit 5
```

### Ch·∫°y monitor

```bash
chmod +x monitor.sh
./monitor.sh
```

## üéØ Tips

1. **S·ª≠ d·ª•ng tmux/screen** ƒë·ªÉ ch·∫°y multiple sessions
2. **Log rotation** ƒë·ªÉ tr√°nh disk full
3. **Regular backup** c·ªßa PostgreSQL data
4. **Monitor disk space** th∆∞·ªùng xuy√™n
5. **Set up alerts** cho GPU memory usage

## üìä Metrics quan tr·ªçng

- **Token usage per request**
- **API response time**
- **GPU memory utilization**
- **Number of traces per project**
- **Error rate**
