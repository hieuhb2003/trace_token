# ğŸš€ vLLM + Langfuse System

Há»‡ thá»‘ng host LLM vá»›i vLLM vÃ  trace token usage qua Langfuse local.

## ğŸ¯ TÃ­nh nÄƒng

- **2 API riÃªng biá»‡t**: Má»—i API cháº¡y trÃªn 1 GPU riÃªng
- **Qwen 2.5 7B**: Model Ä‘Æ°á»£c tá»‘i Æ°u vá»›i GPU memory utilization 0.7
- **Langfuse Local**: Trace token usage local, khÃ´ng cáº§n internet
- **Token Tracking**: Theo dÃµi riÃªng biá»‡t prompt tokens vÃ  completion tokens
- **CLI Tools**: Xem traces vÃ  token usage tá»« terminal
- **Docker Compose**: Dá»… dÃ ng deploy vÃ  quáº£n lÃ½

## ğŸ“‹ YÃªu cáº§u há»‡ thá»‘ng

- Docker vÃ  Docker Compose
- NVIDIA GPU vá»›i CUDA support
- 2 GPU (má»—i GPU cho 1 API)
- NVIDIA Container Toolkit

## ğŸ› ï¸ Setup

### 1. Clone repository

```bash
git clone <your-repo>
cd vllm-langfuse-system
```

### 2. Cáº¥u hÃ¬nh environment

```bash
cp .env.example .env
# Chá»‰nh sá»­a .env náº¿u cáº§n
```

### 3. Khá»Ÿi cháº¡y há»‡ thá»‘ng

```bash
# Sá»­ dá»¥ng script
./start.sh

# Hoáº·c manual
docker-compose up -d
```

## ğŸ”— API Endpoints

### API 1 (GPU 0): http://localhost:8000

### API 2 (GPU 1): http://localhost:8001

### Langfuse Dashboard: http://localhost:3000

## ğŸ“Š Token Usage Tracking

### Xem traces tá»« terminal

```bash
# Xem danh sÃ¡ch traces
python langfuse_cli.py

# Xem chi tiáº¿t trace cá»¥ thá»ƒ
python langfuse_cli.py --trace-id <trace_id>

# Xem tá»•ng token usage tá»« database
python langfuse_cli.py --total-usage

# Xem token usage trong 30 ngÃ y qua
python langfuse_cli.py --total-usage --days 30
```

### Test API

```bash
# Test nhanh
python quick_test.py

# Test chi tiáº¿t
python test_client.py
```

## ğŸ“ˆ Monitoring

### Xem logs

```bash
# Táº¥t cáº£ services
docker-compose logs -f

# Chá»‰ vLLM API 1
docker-compose logs -f vllm-api-1

# Chá»‰ vLLM API 2
docker-compose logs -f vllm-api-2
```

### Kiá»ƒm tra GPU

```bash
nvidia-smi
```

### Health check

```bash
curl http://localhost:8000/health
curl http://localhost:8001/health
```

## ğŸ“ Cáº¥u trÃºc project

```
vllm-langfuse-system/
â”œâ”€â”€ ğŸ“ Docker & Deployment
â”‚   â”œâ”€â”€ docker-compose.yml          # ğŸ³ Docker Compose config
â”‚   â”œâ”€â”€ Dockerfile.vllm             # ğŸ³ Dockerfile cho vLLM
â”‚   â”œâ”€â”€ requirements.txt            # ğŸ“¦ Python dependencies
â”‚   â””â”€â”€ start.sh                    # ğŸš€ Script khá»Ÿi cháº¡y
â”‚
â”œâ”€â”€ ğŸ“ Environment & Config
â”‚   â”œâ”€â”€ .env                        # âš™ï¸ Environment variables
â”‚   â””â”€â”€ .env.example                # ğŸ“ Template
â”‚
â”œâ”€â”€ ğŸ“ Application
â”‚   â””â”€â”€ app/
â”‚       â””â”€â”€ main.py                 # ğŸ vLLM API server
â”‚
â”œâ”€â”€ ğŸ“ Tools & Testing
â”‚   â”œâ”€â”€ langfuse_cli.py             # ğŸ” CLI tool xem traces
â”‚   â”œâ”€â”€ quick_test.py               # âš¡ Test nhanh
â”‚   â””â”€â”€ test_client.py              # ğŸ§ª Test chi tiáº¿t
â”‚
â””â”€â”€ ğŸ“ Documentation
    â”œâ”€â”€ README.md                   # ğŸ“– HÆ°á»›ng dáº«n chÃ­nh
    â””â”€â”€ server_guide.md             # ğŸ–¥ï¸ HÆ°á»›ng dáº«n server
```

## ğŸ¯ Token Usage Features

### 1. **Separate Tracking**

- **Prompt tokens**: Tokens trong input
- **Completion tokens**: Tokens trong response
- **Total tokens**: Tá»•ng cá»§a prompt + completion

### 2. **Database Query**

```bash
# Xem tá»•ng token usage
python langfuse_cli.py --total-usage

# Output:
# ğŸ“Š Tá»”NG TOKEN USAGE TRONG DATABASE
# ğŸ”¢ Tá»•ng sá»‘ requests: 1,234
# ğŸ“¥ Tá»•ng prompt tokens: 45,678
# ğŸ“¤ Tá»•ng completion tokens: 123,456
# ğŸ“Š Tá»•ng tokens: 169,134
```

### 3. **Project-based Tracking**

- PhÃ¢n biá»‡t token usage theo project
- Theo dÃµi riÃªng biá»‡t project-1 vÃ  project-2

## ğŸš¨ Troubleshooting

### GPU khÃ´ng Ä‘Æ°á»£c nháº­n

```bash
nvidia-smi
docker run --rm --gpus all nvidia/cuda:12.1-base-ubuntu22.04 nvidia-smi
```

### API khÃ´ng response

```bash
docker-compose logs vllm-api-1
docker-compose logs vllm-api-2
```

### KhÃ´ng tháº¥y traces

```bash
python quick_test.py
python langfuse_cli.py --total-usage
```

## ğŸ”„ Commands

```bash
# Start services
docker-compose up -d

# Stop services
docker-compose down

# Restart services
docker-compose restart

# View logs
docker-compose logs -f

# Check status
docker-compose ps
```

## ğŸ“ Notes

- Model Ä‘Æ°á»£c cache Ä‘á»ƒ tÄƒng tá»‘c Ä‘á»™ load
- Traces Ä‘Æ°á»£c lÆ°u trong PostgreSQL local
- CÃ³ thá»ƒ scale thÃªm API báº±ng cÃ¡ch thÃªm service
- Token usage Ä‘Æ°á»£c tÃ­nh chÃ­nh xÃ¡c prompt vs completion
